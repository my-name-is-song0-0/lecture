{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "DQN_Cartpole.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "authorship_tag": "ABX9TyP3QitdPmgjZR0zCarg++to"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "2XChBqsRV93V",
    "colab_type": "code",
    "colab": {},
    "executionInfo": {
     "status": "ok",
     "timestamp": 1597890371677,
     "user_tz": -540,
     "elapsed": 15329,
     "user": {
      "displayName": "chang park",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgjyKG1biBtjcsNUuNgPGuo2x0ZVFGiVSztUM3AVg=s64",
      "userId": "11302583505793725879"
     }
    }
   },
   "source": [
    "!apt-get install -y xvfb python-opengl > /dev/null 2>&1\n",
    "!pip install gym pyvirtualdisplay > /dev/null 2>&1"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "leL3oXnCG-3Y",
    "colab_type": "code",
    "colab": {},
    "executionInfo": {
     "status": "ok",
     "timestamp": 1597890376119,
     "user_tz": -540,
     "elapsed": 19765,
     "user": {
      "displayName": "chang park",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgjyKG1biBtjcsNUuNgPGuo2x0ZVFGiVSztUM3AVg=s64",
      "userId": "11302583505793725879"
     }
    }
   },
   "source": [
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "env = gym.make('CartPole-v0').unwrapped\n",
    "\n",
    "# matplotlib 설정\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display as ipythondisplay\n",
    "\n",
    "\n",
    "from pyvirtualdisplay import Display\n",
    "display = Display(visible=0, size=(400, 300))\n",
    "display.start()\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "DURATION_VIEW = False\n",
    "STATE_VIEW = True\n",
    "\n",
    "# GPU를 사용할 경우\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0phcwEhmG_ph",
    "colab_type": "code",
    "colab": {},
    "executionInfo": {
     "status": "ok",
     "timestamp": 1597890376121,
     "user_tz": -540,
     "elapsed": 19766,
     "user": {
      "displayName": "chang park",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgjyKG1biBtjcsNUuNgPGuo2x0ZVFGiVSztUM3AVg=s64",
      "userId": "11302583505793725879"
     }
    }
   },
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"transition 저장\"\"\"\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "s-4ioaa9IFYf",
    "colab_type": "code",
    "colab": {},
    "executionInfo": {
     "status": "ok",
     "timestamp": 1597890376122,
     "user_tz": -540,
     "elapsed": 19764,
     "user": {
      "displayName": "chang park",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgjyKG1biBtjcsNUuNgPGuo2x0ZVFGiVSztUM3AVg=s64",
      "userId": "11302583505793725879"
     }
    }
   },
   "source": [
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self, h, w, outputs):\n",
    "        super(DQN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=5, stride=2)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "\n",
    "        # Linear 입력의 연결 숫자는 conv2d 계층의 출력과 입력 이미지의 크기에\n",
    "        # 따라 결정되기 때문에 따로 계산을 해야합니다.\n",
    "        def conv2d_size_out(size, kernel_size = 5, stride = 2):\n",
    "            return (size - (kernel_size - 1) - 1) // stride  + 1\n",
    "        convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(w)))\n",
    "        convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(h)))\n",
    "        linear_input_size = convw * convh * 32\n",
    "        self.head = nn.Linear(linear_input_size, outputs)\n",
    "\n",
    "    # 최적화 중에 다음 행동을 결정하기 위해서 하나의 요소 또는 배치를 이용해 호촐됩니다.\n",
    "    # ([[left0exp,right0exp]...]) 를 반환합니다.\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        return self.head(x.view(x.size(0), -1))"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4LionNxyLIZ7",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1597890376124,
     "user_tz": -540,
     "elapsed": 19758,
     "user": {
      "displayName": "chang park",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgjyKG1biBtjcsNUuNgPGuo2x0ZVFGiVSztUM3AVg=s64",
      "userId": "11302583505793725879"
     }
    },
    "outputId": "352f01c0-7a47-4573-a13b-b76363a0a60d"
   },
   "source": [
    "resize = T.Compose([T.ToPILImage(),\n",
    "                    T.Resize(40, interpolation=Image.CUBIC),\n",
    "                    T.ToTensor()])\n",
    "\n",
    "\n",
    "def get_cart_location(screen_width):\n",
    "    world_width = env.x_threshold * 2\n",
    "    scale = screen_width / world_width\n",
    "    return int(env.state[0] * scale + screen_width / 2.0)  # MIDDLE OF CART\n",
    "\n",
    "def get_screen():\n",
    "    # gym이 요청한 화면은 400x600x3 이지만, 가끔 800x1200x3 처럼 큰 경우가 있습니다.\n",
    "    # 이것을 Torch order (CHW)로 변환한다.\n",
    "    screen = env.render(mode='rgb_array').transpose((2, 0, 1))\n",
    "    # 카트는 아래쪽에 있으므로 화면의 상단과 하단을 제거하십시오.\n",
    "    _, screen_height, screen_width = screen.shape\n",
    "    screen = screen[:, int(screen_height*0.4):int(screen_height * 0.8)]\n",
    "    view_width = int(screen_width * 0.6)\n",
    "    cart_location = get_cart_location(screen_width)\n",
    "    if cart_location < view_width // 2:\n",
    "        slice_range = slice(view_width)\n",
    "    elif cart_location > (screen_width - view_width // 2):\n",
    "        slice_range = slice(-view_width, None)\n",
    "    else:\n",
    "        slice_range = slice(cart_location - view_width // 2,\n",
    "                            cart_location + view_width // 2)\n",
    "    # 카트를 중심으로 정사각형 이미지가 되도록 가장자리를 제거하십시오.\n",
    "    screen = screen[:, :, slice_range]\n",
    "    # float 으로 변환하고,  rescale 하고, torch tensor 로 변환하십시오.\n",
    "    # (이것은 복사를 필요로하지 않습니다)\n",
    "    screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
    "    screen = torch.from_numpy(screen)\n",
    "    # 크기를 수정하고 배치 차원(BCHW)을 추가하십시오.\n",
    "    return resize(screen).unsqueeze(0).to(device)\n",
    "\n",
    "env.reset()"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([-0.03474165, -0.01370952, -0.04796394,  0.00339731])"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 5
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VpOMCa2oTfyf",
    "colab_type": "code",
    "colab": {},
    "executionInfo": {
     "status": "ok",
     "timestamp": 1597890377242,
     "user_tz": -540,
     "elapsed": 20873,
     "user": {
      "displayName": "chang park",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgjyKG1biBtjcsNUuNgPGuo2x0ZVFGiVSztUM3AVg=s64",
      "userId": "11302583505793725879"
     }
    }
   },
   "source": [
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.999\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 200\n",
    "TARGET_UPDATE = 10\n",
    "\n",
    "# AI gym에서 반환된 형태를 기반으로 계층을 초기화 하도록 화면의 크기를\n",
    "# 가져옵니다. 이 시점에 일반적으로 3x40x90 에 가깝습니다.\n",
    "# 이 크기는 get_screen()에서 고정, 축소된 렌더 버퍼의 결과입니다.\n",
    "init_screen = get_screen()\n",
    "_, _, screen_height, screen_width = init_screen.shape\n",
    "\n",
    "# gym 행동 공간에서 행동의 숫자를 얻습니다.\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "policy_net = DQN(screen_height, screen_width, n_actions).to(device)\n",
    "target_net = DQN(screen_height, screen_width, n_actions).to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()\n",
    "\n",
    "optimizer = optim.RMSprop(policy_net.parameters())\n",
    "memory = ReplayMemory(10000)\n",
    "\n",
    "\n",
    "steps_done = 0\n",
    "\n",
    "\n",
    "def select_action(state):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "        math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            # t.max (1)은 각 행의 가장 큰 열 값을 반환합니다.\n",
    "            # 최대 결과의 두번째 열은 최대 요소의 주소값이므로,\n",
    "            # 기대 보상이 더 큰 행동을 선택할 수 있습니다.\n",
    "            return policy_net(state).max(1)[1].view(1, 1)\n",
    "    else:\n",
    "        return torch.tensor([[random.randrange(n_actions)]], device=device, dtype=torch.long)\n",
    "\n",
    "\n",
    "episode_durations = []\n",
    "\n",
    "def plot_durations():\n",
    "    ipythondisplay.clear_output(wait=True)\n",
    "\n",
    "    plt.figure(2)\n",
    "    plt.clf()\n",
    "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
    "    plt.title('Training...')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Duration')\n",
    "    plt.plot(durations_t.numpy())\n",
    "    # Take 100 episode averages and plot them too\n",
    "    if len(durations_t) >= 100:\n",
    "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
    "        means = torch.cat((torch.zeros(99), means))\n",
    "        plt.plot(means.numpy())\n",
    "\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "KEh5L3QgWoTH",
    "colab_type": "code",
    "colab": {},
    "executionInfo": {
     "status": "ok",
     "timestamp": 1597890377243,
     "user_tz": -540,
     "elapsed": 20873,
     "user": {
      "displayName": "chang park",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgjyKG1biBtjcsNUuNgPGuo2x0ZVFGiVSztUM3AVg=s64",
      "userId": "11302583505793725879"
     }
    }
   },
   "source": [
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
    "    # detailed explanation). 이것은 batch-array의 Transitions을 Transition의 batch-arrays로\n",
    "    # 전환합니다.\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    # 최종이 아닌 상태의 마스크를 계산하고 배치 요소를 연결합니다\n",
    "    # (최종 상태는 시뮬레이션이 종료 된 이후의 상태)\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)), device=device, dtype=torch.bool)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                                if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    # Q(s_t, a) 계산 - 모델이 Q(s_t)를 계산하고, 취한 행동의 열을 선택합니다.\n",
    "    # 이들은 policy_net에 따라 각 배치 상태에 대해 선택된 행동입니다.\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "    # 모든 다음 상태를 위한 V(s_{t+1}) 계산\n",
    "    # non_final_next_states의 행동들에 대한 기대값은 \"이전\" target_net을 기반으로 계산됩니다.\n",
    "    # max(1)[0]으로 최고의 보상을 선택하십시오.\n",
    "    # 이것은 마스크를 기반으로 병합되어 기대 상태 값을 갖거나 상태가 최종인 경우 0을 갖습니다.\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0].detach()\n",
    "    # 기대 Q 값 계산\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    # Huber 손실 계산\n",
    "    loss = F.smooth_l1_loss(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "    # 모델 최적화\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    for param in policy_net.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "j1fo83lkWrR4",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "executionInfo": {
     "status": "error",
     "timestamp": 1597890448929,
     "user_tz": -540,
     "elapsed": 92555,
     "user": {
      "displayName": "chang park",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgjyKG1biBtjcsNUuNgPGuo2x0ZVFGiVSztUM3AVg=s64",
      "userId": "11302583505793725879"
     }
    },
    "outputId": "d091011d-e9a3-45f3-9ed8-5ace39a8c0a7"
   },
   "source": [
    "num_episodes = 50\n",
    "for i_episode in range(num_episodes):\n",
    "    # 환경과 상태 초기화\n",
    "    env.reset()\n",
    "    last_screen = get_screen()\n",
    "    current_screen = get_screen()\n",
    "    state = current_screen - last_screen\n",
    "    for t in count():\n",
    "        # 행동 선택과 수행\n",
    "        action = select_action(state)\n",
    "        _, reward, done, _ = env.step(action.item())\n",
    "        reward = torch.tensor([reward], device=device)\n",
    "\n",
    "        # 새로운 상태 관찰\n",
    "        last_screen = current_screen\n",
    "        current_screen = get_screen()\n",
    "        if not done:\n",
    "            next_state = current_screen - last_screen\n",
    "        else:\n",
    "            next_state = None\n",
    "\n",
    "        # 메모리에 변이 저장\n",
    "        memory.push(state, action, next_state, reward)\n",
    "\n",
    "        # 다음 상태로 이동\n",
    "        state = next_state\n",
    "\n",
    "        # 최적화 한단계 수행(목표 네트워크에서)\n",
    "        optimize_model()\n",
    "        \n",
    "        if STATE_VIEW:\n",
    "            ipythondisplay.clear_output(wait=True)\n",
    "            plt.clf()\n",
    "            plt.imshow(get_screen().cpu().squeeze(0).permute(1, 2, 0).numpy())\n",
    "            plt.show()\n",
    "        \n",
    "        if done:\n",
    "            episode_durations.append(t + 1)\n",
    "            if DURATION_VIEW:\n",
    "                plot_durations()\n",
    "\n",
    "            break\n",
    "    #목표 네트워크 업데이트, 모든 웨이트와 바이어스 복사\n",
    "    if i_episode % TARGET_UPDATE == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "print('Complete')\n",
    "env.render()\n",
    "env.close()\n",
    "plt.ioff()\n",
    "plt.show()"
   ],
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-8-742087026b20>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     27\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     28\u001B[0m         \u001B[0;31m# 최적화 한단계 수행(목표 네트워크에서)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 29\u001B[0;31m         \u001B[0moptimize_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     30\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     31\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mSTATE_VIEW\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-7-c99ebdb599ac>\u001B[0m in \u001B[0;36moptimize_model\u001B[0;34m()\u001B[0m\n\u001B[1;32m     36\u001B[0m     \u001B[0;31m# 모델 최적화\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     37\u001B[0m     \u001B[0moptimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mzero_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 38\u001B[0;31m     \u001B[0mloss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     39\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0mparam\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mpolicy_net\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mparameters\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     40\u001B[0m         \u001B[0mparam\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgrad\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclamp_\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001B[0m in \u001B[0;36mbackward\u001B[0;34m(self, gradient, retain_graph, create_graph)\u001B[0m\n\u001B[1;32m    183\u001B[0m                 \u001B[0mproducts\u001B[0m\u001B[0;34m.\u001B[0m \u001B[0mDefaults\u001B[0m \u001B[0mto\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m`\u001B[0m\u001B[0;31m`\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;31m`\u001B[0m\u001B[0;31m`\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    184\u001B[0m         \"\"\"\n\u001B[0;32m--> 185\u001B[0;31m         \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mautograd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgradient\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    186\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    187\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mregister_hook\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhook\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001B[0m in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001B[0m\n\u001B[1;32m    125\u001B[0m     Variable._execution_engine.run_backward(\n\u001B[1;32m    126\u001B[0m         \u001B[0mtensors\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgrad_tensors\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 127\u001B[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001B[0m\u001B[1;32m    128\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    129\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": [],
      "needs_background": "light"
     }
    }
   ]
  }
 ]
}